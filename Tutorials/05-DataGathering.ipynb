{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> Data Gathering </h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Data Gathering is simply the process of collecting your data together. It can encompass anything from launching a data collection project, web scraping, pulling from a database, downloading data in bulk, to actually calling someone to ask if you can use some of their data. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Where to get Data</center></h2>\n",
    "\n",
    "### The Web \n",
    "\n",
    "The web is absolutely full of data or ways to get data, either by hosting **data repositories** from which you can download data, by offering **APIs** through which you can request specific data from particular applications, or as data itself, such that you can use **web scraping** to extract data directly from websites. \n",
    "\n",
    "### Other than the Web\n",
    "\n",
    "Not all data is indexed or accessible on the web, at least not publicly. Sometimes finding data means chasing down data wherever it might be - if there is some particular data you need, figure out who might have it, and getting in touch. \n",
    "\n",
    "Companies, research labs, non-profits, etc will probably host their data 'in house' potentially as raw data files, but more likely in some kind of formal database. If you have access to interesting databases through these kinds of organizations, then you will need to interbase with databases, using database queries, to gather your data. \n",
    "\n",
    "\n",
    "### Data Gathering Skills\n",
    "Depending on your gathering method, you will likely have to do some combination of the following:\n",
    "- Download data files from repositories\n",
    "- Read data files into python (covered in 06-DataWrangling)\n",
    "- Use APIs \n",
    "- Query databases\n",
    "- Call someone and ask them to send you a harddrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Repositories\n",
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "A Data Repository is basically just a place that data is stored. For our purposes, it is a place you can download data from. \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "A good list of available data repositories: http://www.kdnuggets.com/datasets/index.html\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA.GOV\n",
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "Data.gov is the US Federal Governments publicly available data repository. It has tons of different datasets, all available for download. \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Check out what data is available on data.gov here: https://www.data.gov/\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<br>\n",
    "<img src=\"img/data_gov.png\" alt=\"gov_dat\" height=\"500\" width=\"750\">\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### San Diego City Data\n",
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "The City of San Diego also has a data repository for publicly available San Diego city data. \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Check out what data is available from the city of San Diego here: https://data.sandiego.gov/\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img src=\"img/sd_data.png\" alt=\"sd_dat\" height=\"500\" width=\"750\">\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Databases\n",
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "A database is an organized collection of data. More formally, 'database' refers to a set of related data, and the way it is organized. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured Query Language - SQL\n",
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "SQL (pronounced 'sequel') is a language used to 'communicate' with databases. In particular, it the standard way to interface with [relational database management systems]. SQL is the most popular language for database management, although there are multiple variants of SQL, with slight differences. \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "There is a useful introduction and tutorial to SQL [here](http://www.sqlcourse.com/intro.html), and a couple useful cheat sheets [here](http://www.cheat-sheets.org/sites/sql.su/), and [here](http://www.sqltutorial.org/wp-content/uploads/2016/04/SQL-cheat-sheet.pdf).\n",
    "</div>\n",
    "\n",
    "Note: Although you can, you will not necessarily have to use SQL for this class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application Program Interfaces (APIs)\n",
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "APIs are basically a way for software to talk to software - it is an interface into an application / website / database designed for software. APIs offer a lot of functionality - you can send requests to the application to do all kinds of actions - a subset of them being as ways to collect data from the application.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "For a simple explanation of APIs go [here](https://medium.freecodecamp.com/what-is-an-api-in-english-please-b880a3214a82), or for a much broader, more technical, overview (but much more than you need to know right now) try [here](https://medium.com/@mattburgess/apis-a-basic-primer-f8250602597d).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "#  requests lets you make http requests from python\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, APIs are usually special URLs that return raw data (json or XML) as opposed to a web page to be rendered for human viewers (html). Find the documentation for a particular API to see how you send requests to access whatever data you want. For example, let's try the Github API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Request data from the Github API on a particular user\n",
    "page = requests.get('https://api.github.com/users/tomdonoghue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"login\":\"TomDonoghue\",\"id\":7727566,\"avatar_url\":\"https://avatars3.githubusercontent.com/u/7727566?v=3\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/TomDonoghue\",\"html_url\":\"https://github.com/TomDonoghue\",\"followers_url\":\"https://api.github.com/users/TomDonoghue/followers\",\"following_url\":\"https://api.github.com/users/TomDonoghue/following{/other_user}\",\"gists_url\":\"https://api.github.com/users/TomDonoghue/gists{/gist_id}\",\"starred_url\":\"https://api.github.com/users/TomDonoghue/starred{/owner}{/repo}\",\"subscriptions_url\":\"https://api.github.com/users/TomDonoghue/subscriptions\",\"organizations_url\":\"https://api.github.com/users/TomDonoghue/orgs\",\"repos_url\":\"https://api.github.com/users/TomDonoghue/repos\",\"events_url\":\"https://api.github.com/users/TomDonoghue/events{/privacy}\",\"received_events_url\":\"https://api.github.com/users/TomDonoghue/received_events\",\"type\":\"User\",\"site_admin\":false,\"name\":\"Tom\",\"company\":\"UC San Diego\",\"blog\":\"tomdonoghue.github.io\",\"location\":\"San Diego\",\"email\":\"thomasdonoghue@hotmail.ca\",\"hireable\":null,\"bio\":\"Cognitive Science Grad Student @ UCSD. \\\\r\\\\nOn Twitter @TomDonoghue\",\"public_repos\":6,\"public_gists\":0,\"followers\":2,\"following\":9,\"created_at\":\"2014-05-28T20:20:48Z\",\"updated_at\":\"2017-04-13T21:55:58Z\"}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The content we get back is a json file\n",
    "page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avatar_url             https://avatars3.githubusercontent.com/u/77275...\n",
       "bio                    Cognitive Science Grad Student @ UCSD. \\r\\nOn ...\n",
       "blog                                               tomdonoghue.github.io\n",
       "company                                                     UC San Diego\n",
       "created_at                                          2014-05-28T20:20:48Z\n",
       "email                                          thomasdonoghue@hotmail.ca\n",
       "events_url             https://api.github.com/users/TomDonoghue/event...\n",
       "followers                                                              2\n",
       "followers_url          https://api.github.com/users/TomDonoghue/follo...\n",
       "following                                                              9\n",
       "following_url          https://api.github.com/users/TomDonoghue/follo...\n",
       "gists_url              https://api.github.com/users/TomDonoghue/gists...\n",
       "gravatar_id                                                             \n",
       "hireable                                                            None\n",
       "html_url                                  https://github.com/TomDonoghue\n",
       "id                                                               7727566\n",
       "location                                                       San Diego\n",
       "login                                                        TomDonoghue\n",
       "name                                                                 Tom\n",
       "organizations_url          https://api.github.com/users/TomDonoghue/orgs\n",
       "public_gists                                                           0\n",
       "public_repos                                                           6\n",
       "received_events_url    https://api.github.com/users/TomDonoghue/recei...\n",
       "repos_url                 https://api.github.com/users/TomDonoghue/repos\n",
       "site_admin                                                         False\n",
       "starred_url            https://api.github.com/users/TomDonoghue/starr...\n",
       "subscriptions_url      https://api.github.com/users/TomDonoghue/subsc...\n",
       "type                                                                User\n",
       "updated_at                                          2017-04-13T21:55:58Z\n",
       "url                             https://api.github.com/users/TomDonoghue\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can read in the json data with pandas\n",
    "pd.read_json(page.content, typ='series')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "This link lists some commonly used APIs: http://www.webopedia.com/TERM/A/API.html\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping\n",
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "Web scraping is when you (programmatically) extract data from websites. While API calls can be considered 'web scraping', scraping typically refers to the more hands-on requirements of getting data from websites when there is no API - trawling through pages, and extracting data of interest. \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "More information on web scraping (wikipedia): https://en.wikipedia.org/wiki/Web_scraping\n",
    "</div>\n",
    "\n",
    "Note:\n",
    "Be aware that scraping data from websites (without using APIs) can often be an involved project itself - scraping sites can take a considerable amount of tuning to get the data you want. If you try scraping websites, also make sure you are allowed to scrape the data, and follow the websites terms of service. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
